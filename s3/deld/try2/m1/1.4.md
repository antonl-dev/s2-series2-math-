# Module 1: Number Systems and Logic Gate Fundamentals

## 1.4 Fixed-Point and Floating-Point Representation

So far, we have dealt with integers or simple fractions. To represent a wider range of real numbers (numbers with fractional parts) efficiently, digital systems use two main methods: fixed-point and floating-point representation.

### 1. Fixed-Point Representation

In fixed-point representation, the position of the binary point is **fixed and implicit**. The programmer and the hardware must agree on where the binary point is located. It is not explicitly stored as part of the number.

This format divides the bits of a binary word into two parts: an **integer part** and a **fractional part**.

> **Visual Aid:** A simple block diagram clarifies the format.
>
> [Click here for a Fixed-Point Representation Diagram](https://www.google.com/search?tbm=isch&q=fixed+point+number+representation+diagram)
>
> **What to look for:** A rectangle representing a binary word, divided into sections labeled "Sign Bit", "Integer Part", and "Fractional Part". This clearly shows the pre-defined structure.

**Format:**
Let's consider an 8-bit number with 4 bits for the integer part and 4 bits for the fractional part.

`IIII.FFFF`
-   The leftmost bit is often used for the sign (in signed representations).
-   The remaining `I` bits represent the integer magnitude.
-   The `F` bits represent the fractional magnitude.

**Example:** Represent `+5.75` using an 8-bit fixed-point format with 1 sign bit, 3 integer bits, and 4 fractional bits.

1.  **Sign:** The number is positive, so the sign bit is `0`.
2.  **Integer Part (5):** `5₁₀ = 101₂`.
3.  **Fractional Part (0.75):** `0.75₁₀ = .11₂`. To fill 4 fractional bits, we pad with zeros: `.1100₂`.

Combining these parts:
`Sign | Integer | Fractional`
`  0  |   101   |   1100  `

The final 8-bit fixed-point representation is `01011100`.

**Advantages:**
*   **Simplicity:** Arithmetic operations (addition, subtraction) are simple and fast, as they work just like integer operations.
*   **Low Cost:** Requires less complex hardware than floating-point.

**Disadvantages:**
*   **Limited Range:** The maximum and minimum values that can be represented are small.
*   **Limited Precision:** The precision (the smallest fractional part) is fixed. It cannot represent very large and very small numbers simultaneously.

Fixed-point is suitable for applications where the range of numbers is well-known and limited, such as in digital signal processing and embedded controllers.

### 2. Floating-Point Representation

Floating-point representation overcomes the range limitations of fixed-point by representing numbers in a format analogous to scientific notation. This allows it to handle a vast range of values, from very small to very large.

The standard format is defined by the **IEEE 754 standard**. A number is represented in three parts:

**N = (-1)<sup>S</sup> × M × 2<sup>E</sup>**

1.  **Sign (S):** A single bit. `0` for positive, `1` for negative.
2.  **Exponent (E):** A group of bits that represents the exponent value. It is stored in a **biased format** to allow for both positive and negative exponents without needing a separate sign bit for the exponent itself.
3.  **Mantissa (M) or Significand/Fraction:** A group of bits that represents the precision bits of the number. In normalized form, it is `1.fraction`. The leading `1` is usually implicit (not stored) to gain an extra bit of precision.

#### IEEE 754 Standard Formats

*   **Single-Precision (32 bits):**
    *   **Sign:** 1 bit
    *   **Exponent:** 8 bits (with a bias of **127**)
    *   **Mantissa:** 23 bits (representing a 24-bit number due to the implicit leading `1`)

    > **Visual Aid:** This format is best understood with a diagram.
    >
    > [Click here for the IEEE 754 Single-Precision Format Diagram](https://www.google.com/search?tbm=isch&q=ieee+754+single+precision+format+diagram)
    >
    > **What to look for:** A diagram showing a 32-bit register. It must be clearly divided into three sections: the Sign bit (bit 31), the Exponent (bits 30-23), and the Mantissa/Fraction (bits 22-0). This visual layout is crucial.

    `[ S | EEEEEEEE | MMMMMMMMMMMMMMMMMMMMMMM ]`
    `bit 31 | bits 30-23 | bits 22-0`

*   **Double-Precision (64 bits):**
    *   **Sign:** 1 bit
    *   **Exponent:** 11 bits (with a bias of **1023**)
    *   **Mantissa:** 52 bits

#### Conversion to IEEE 754 Single-Precision Format

**Example:** Convert `-12.625₁₀` to 32-bit floating-point format.

**Step 1: Determine the Sign Bit (S)**
The number is negative, so **S = 1**.

**Step 2: Convert the Magnitude to Binary**
*   Integer part: `12₁₀ = 1100₂`
*   Fractional part: `0.625₁₀ = .101₂`
*   Combined: `12.625₁₀ = 1100.101₂`

**Step 3: Normalize the Binary Number**
Normalize the number so there is only one non-zero digit to the left of the binary point.
`1100.101 = 1.100101 × 2³`
The actual exponent is **3**.

**Step 4: Calculate the Biased Exponent (E)**
`Biased Exponent = Actual Exponent + Bias`. For single-precision, the bias is 127.
`E = 3 + 127 = 130`
Convert `130₁₀` to an 8-bit binary number: `130₁₀ = 10000010₂`.

**Step 5: Determine the Mantissa (M)**
The mantissa is the fractional part of the normalized number.
Normalized number: `1.100101`
Mantissa (23 bits): `10010100000000000000000` (pad with zeros).

**Step 6: Assemble the Final 32-bit Number**
`[ 1 | 10000010 | 10010100000000000000000 ]`

---

### Questions

1.  What is the fundamental difference between how the binary point is handled in fixed-point versus floating-point representation?
2.  Represent the number `-2.5` using a 6-bit fixed-point format with 1 sign bit, 2 integer bits, and 3 fractional bits.
3.  Convert the decimal number `13.5₁₀` into the 32-bit single-precision IEEE 754 floating-point format.
4.  In the IEEE 754 standard, why is the exponent stored in a "biased" format instead of using a 2's complement representation?
5.  What are the main advantages of using floating-point representation over fixed-point?
