# Module 4.1.a: Introduction to Sorting & Basic Sorting Algorithms

## 1. Introduction to Sorting

Sorting is the process of arranging a collection of items in a particular order. The most common orders are numerical order (for numbers) and lexicographical (alphabetical) order (for strings).

A sorting algorithm is a specific procedure for accomplishing this task. Efficient sorting is crucial for optimizing the performance of other algorithms (like search algorithms) and for presenting data in a more readable format.

### Key Concepts in Sorting

#### a. In-place vs. Not-in-place Sorting

-   **In-place Sorting:** An algorithm that sorts the elements within the original array, using only a constant amount of extra memory (O(1)) for temporary variables. It does not create a new array to store the sorted data.
    -   *Example:* Bubble Sort, Selection Sort, Insertion Sort.
-   **Not-in-place (or Out-of-place) Sorting:** An algorithm that requires extra space, often proportional to the number of elements being sorted (O(n)), to store the data. It typically creates a new array or data structure to hold the sorted elements.
    -   *Example:* Merge Sort.

#### b. Stable vs. Unstable Sorting

This property is important when sorting elements with equal keys or values.

-   **Stable Sorting:** A sorting algorithm is stable if it preserves the original relative order of equal elements. If two items have equal keys, they will remain in the same order in the sorted output as they were in the input.
    -   *Example:* Bubble Sort, Insertion Sort, Merge Sort.
-   **Unstable Sorting:** An algorithm that does not guarantee the original relative order of equal elements.
    -   *Example:* Selection Sort, Quick Sort, Heap Sort.

**Example of Stability:**
Consider sorting the following pairs based on the number: `(5, a), (3, b), (5, c), (2, d)`
-   **Input:** `[(5, a), (3, b), (5, c), (2, d)]`
-   **Stable Sort Output:** `[(2, d), (3, b), (5, a), (5, c)]` (The relative order of `(5, a)` and `(5, c)` is maintained).
-   **Unstable Sort Output (Possible):** `[(2, d), (3, b), (5, c), (5, a)]` (The relative order of `(5, a)` and `(5, c)` is *not* guaranteed).

[**Google Image Search:** `stable vs unstable sorting algorithm`](https://www.google.com/search?tbm=isch&q=stable+vs+unstable+sorting+algorithm)
*   **What to look for:** A diagram showing elements with two attributes (e.g., a number and a color). The "before" state shows some elements with the same number but different colors. The "after" state for a stable sort shows these elements still in their original color order, while the unstable sort might have them swapped.

#### c. Adaptive vs. Non-Adaptive Sorting

-   **Adaptive Sorting:** The algorithm's performance adapts to the initial level of sortedness in the input data. It runs faster if the input is already partially or fully sorted.
    -   *Example:* Bubble Sort (with an optimization flag), Insertion Sort.
-   **Non-Adaptive Sorting:** The algorithm's performance is independent of the initial order of elements. It performs the same sequence of operations regardless of whether the input is sorted or not.
    -   *Example:* Selection Sort, Heap Sort.

---

## 2. Bubble Sort

Bubble Sort is a simple comparison-based algorithm. It repeatedly steps through the list, compares each pair of adjacent items, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted. The algorithm gets its name because smaller or larger elements "bubble" to their correct position.

### Algorithm (Pseudocode)

```
procedure bubbleSort(list)
  n = length of list
  do
    swapped = false
    for i from 0 to n-2
      if list[i] > list[i+1]
        swap(list[i], list[i+1])
        swapped = true
      end if
    end for
    n = n - 1 // Optimization: last element is now sorted
  while swapped
end procedure
```
The `swapped` flag is an optimization. If a full pass is completed without any swaps, the list is already sorted, and the algorithm can terminate early.

### C Code Example

```c
#include <stdio.h>

void swap(int *xp, int *yp) {
    int temp = *xp;
    *xp = *yp;
    *yp = temp;
}

void bubbleSort(int arr[], int n) {
    int i, j;
    int swapped;
    for (i = 0; i < n - 1; i++) {
        swapped = 0; // Flag to check if swap happened
        // Last i elements are already in place
        for (j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                swap(&arr[j], &arr[j + 1]);
                swapped = 1;
            }
        }
        // If no two elements were swapped by inner loop, then break
        if (swapped == 0)
            break;
    }
}

void printArray(int arr[], int size) {
    for (int i = 0; i < size; i++)
        printf("%d ", arr[i]);
    printf("\n");
}

int main() {
    int arr[] = {35, 33, 42, 10, 14, 19};
    int n = sizeof(arr) / sizeof(arr[0]);
    printf("Unsorted array: \n");
    printArray(arr, n);

    bubbleSort(arr, n);

    printf("Sorted array: \n");
    printArray(arr, n);
    return 0;
}
```

### Complexity Analysis
-   **Time Complexity:**
    -   **Worst Case:** O(n²) - When the array is reverse sorted.
    -   **Average Case:** O(n²)
    -   **Best Case:** O(n) - When the array is already sorted, and the `swapped` flag optimization is used, it takes only one pass.
-   **Space Complexity:** O(1) - It is an in-place sorting algorithm.

### Characteristics
-   **In-place:** Yes
-   **Stable:** Yes
-   **Adaptive:** Yes (with the flag optimization)

[**Google Image Search:** `bubble sort algorithm animation`](https://www.google.com/search?tbm=isch&q=bubble+sort+algorithm+animation)
*   **What to look for:** A GIF or a series of diagrams showing adjacent elements being compared and swapped. The largest unsorted element should "bubble" to the end of the unsorted section in each pass.

---

## 3. Insertion Sort

Insertion Sort is another simple, comparison-based algorithm. It builds the final sorted array one item at a time. It iterates through the input elements and, for each element, it finds the correct position in the already sorted part of the array and inserts it there.

### Algorithm (Pseudocode)

```
procedure insertionSort(list)
  for i from 1 to length(list)-1
    key = list[i]
    j = i - 1
    // Move elements of list[0..i-1], that are greater than key,
    // to one position ahead of their current position
    while j >= 0 and list[j] > key
      list[j+1] = list[j]
      j = j - 1
    end while
    list[j+1] = key
  end for
end procedure
```

### C Code Example

```c
#include <stdio.h>

void insertionSort(int arr[], int n) {
    int i, key, j;
    for (i = 1; i < n; i++) {
        key = arr[i];
        j = i - 1;

        // Move elements of arr[0..i-1] that are greater than key
        // to one position ahead of their current position
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j = j - 1;
        }
        arr[j + 1] = key;
    }
}

// Function to print an array
void printArray(int arr[], int size) {
    for (int i = 0; i < size; i++)
        printf("%d ", arr[i]);
    printf("\n");
}

int main() {
    int arr[] = {14, 33, 27, 10, 35};
    int n = sizeof(arr) / sizeof(arr[0]);
    printf("Unsorted array: \n");
    printArray(arr, n);

    insertionSort(arr, n);

    printf("Sorted array: \n");
    printArray(arr, n);
    return 0;
}
```

### Complexity Analysis
-   **Time Complexity:**
    -   **Worst Case:** O(n²) - When the array is reverse sorted.
    -   **Average Case:** O(n²)
    -   **Best Case:** O(n) - When the array is already sorted, the inner `while` loop condition is never met.
-   **Space Complexity:** O(1) - It is an in-place sorting algorithm.

### Characteristics
-   **In-place:** Yes
-   **Stable:** Yes
-   **Adaptive:** Yes (Efficient for data sets that are already substantially sorted).

[**Google Image Search:** `insertion sort algorithm animation`](https://www.google.com/search?tbm=isch&q=insertion+sort+algorithm+animation)
*   **What to look for:** A diagram showing a "sorted" and "unsorted" portion of the array. The algorithm picks an element from the unsorted part and shifts elements in the sorted part to make space for it.

---

## 4. Selection Sort

Selection Sort is an in-place comparison-based algorithm. The list is divided into two parts: a sorted sublist which is built up from left to right, and an unsorted sublist that occupies the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire list. The algorithm proceeds by finding the smallest element in the unsorted sublist and swapping it with the leftmost unsorted element, moving it to the sorted sublist.

### Algorithm (Pseudocode)

```
procedure selectionSort(list)
  n = length of list
  for i from 0 to n-2
    // Find the minimum element in unsorted list[i..n-1]
    min_index = i
    for j from i+1 to n-1
      if list[j] < list[min_index]
        min_index = j
      end if
    end for
    // Swap the found minimum element with the first element
    swap(list[min_index], list[i])
  end for
end procedure
```

### C Code Example

```c
#include <stdio.h>

void swap(int *xp, int *yp) {
    int temp = *xp;
    *xp = *yp;
    *yp = temp;
}

void selectionSort(int arr[], int n) {
    int i, j, min_idx;
    // One by one move boundary of unsorted subarray
    for (i = 0; i < n - 1; i++) {
        // Find the minimum element in unsorted array
        min_idx = i;
        for (j = i + 1; j < n; j++) {
            if (arr[j] < arr[min_idx])
                min_idx = j;
        }
        // Swap the found minimum element with the first element
        swap(&arr[min_idx], &arr[i]);
    }
}

void printArray(int arr[], int size) {
    for (int i = 0; i < size; i++)
        printf("%d ", arr[i]);
    printf("\n");
}

int main() {
    int arr[] = {14, 33, 27, 10, 35};
    int n = sizeof(arr) / sizeof(arr[0]);
    printf("Unsorted array: \n");
    printArray(arr, n);

    selectionSort(arr, n);

    printf("Sorted array: \n");
    printArray(arr, n);
    return 0;
}
```

### Complexity Analysis
-   **Time Complexity:**
    -   **Worst Case:** O(n²)
    -   **Average Case:** O(n²)
    -   **Best Case:** O(n²) - The algorithm always scans the entire unsorted part to find the minimum, regardless of the initial order.
-   **Space Complexity:** O(1) - It is an in-place sorting algorithm.

### Characteristics
-   **In-place:** Yes
-   **Stable:** No (by default, as it can swap distant elements).
-   **Adaptive:** No.

[**Google Image Search:** `selection sort algorithm animation`](https://www.google.com/search?tbm=isch&q=selection+sort+algorithm+animation)
*   **What to look for:** A diagram where each pass scans the "unsorted" part of the array to find the minimum value. This minimum value is then swapped with the first element of the unsorted part.

---

### Questions

<details>
  <summary><b>1. Explain the difference between stable and unstable sorting algorithms. Provide an example to illustrate.</b></summary>
  
  A sorting algorithm is called **stable** if it preserves the original relative order of elements with equal keys. If an input list has two items with the same key, a stable algorithm ensures they appear in the same order in the output as they did in the input. An **unstable** algorithm does not provide this guarantee.

  **Example:**
  Suppose we have a list of tuples `(value, letter)` to be sorted by `value`:
  `Input: [(4, 'A'), (2, 'B'), (4, 'C')]`

  - A **stable** sort will always produce: `[(2, 'B'), (4, 'A'), (4, 'C')]`. The original order of `(4, 'A')` before `(4, 'C')` is maintained.
  - An **unstable** sort might produce: `[(2, 'B'), (4, 'C'), (4, 'A')]`. Here, the relative order of the two `4`s has been changed.

  Stability is useful when data needs to be sorted on multiple criteria. For example, sorting a list of students by name (primary key) and then by grade (secondary key).
</details>

<details>
  <summary><b>2. Write the algorithm for Insertion Sort and analyze its best, worst, and average-case time complexities.</b></summary>

  **Algorithm (Pseudocode):**
  ```
  procedure insertionSort(list)
    // Start from the second element (element at index 1)
    for i from 1 to length(list)-1
      key = list[i] // The element to be inserted
      j = i - 1

      // Move elements of the sorted sub-array (list[0..i-1])
      // that are greater than the key one position to the right
      while j >= 0 and list[j] > key
        list[j+1] = list[j]
        j = j - 1
      end while
      
      // Insert the key into its correct position
      list[j+1] = key
    end for
  end procedure
  ```

  **Complexity Analysis:**
  - **Best Case: O(n)**
    - This occurs when the input array is already sorted. The outer loop runs `n-1` times, but the inner `while` loop condition (`list[j] > key`) is never true. Therefore, only a single comparison is made in the inner loop for each element, leading to a linear time complexity.
  - **Worst Case: O(n²)**
    - This occurs when the input array is sorted in reverse order. For each element `i`, the algorithm must shift all `i-1` elements in the sorted sub-array to the right. This results in a total number of comparisons and shifts proportional to `1 + 2 + 3 + ... + (n-1)`, which is `(n(n-1))/2`, giving a complexity of O(n²).
  - **Average Case: O(n²)**
    - For a randomly ordered array, each element on average needs to be shifted past half of the elements in the sorted sub-array. This still results in a quadratic time complexity.
</details>

<details>
  <summary><b>3. Trace the execution of Bubble Sort on the array `[6, 5, 3, 1, 8, 7]`. Show the state of the array after each complete pass.</b></summary>
  
  **Initial Array:** `[6, 5, 3, 1, 8, 7]`

  **Pass 1:**
  - `[5, 6, 3, 1, 8, 7]` (Swap 6, 5)
  - `[5, 3, 6, 1, 8, 7]` (Swap 6, 3)
  - `[5, 3, 1, 6, 8, 7]` (Swap 6, 1)
  - `[5, 3, 1, 6, 8, 7]` (No swap for 8, 6)
  - `[5, 3, 1, 6, 7, 8]` (Swap 8, 7)
  - **After Pass 1:** `[5, 3, 1, 6, 7, 8]` (The largest element, 8, is in its correct place)

  **Pass 2:**
  - `[3, 5, 1, 6, 7, 8]` (Swap 5, 3)
  - `[3, 1, 5, 6, 7, 8]` (Swap 5, 1)
  - ... (No more swaps in this pass as 5 < 6, 6 < 7)
  - **After Pass 2:** `[3, 1, 5, 6, 7, 8]` (The second largest, 7, is in its correct place)

  **Pass 3:**
  - `[1, 3, 5, 6, 7, 8]` (Swap 3, 1)
  - ... (No more swaps)
  - **After Pass 3:** `[1, 3, 5, 6, 7, 8]` (The third largest, 6, is in its correct place)

  **Pass 4:**
  - The inner loop runs. It compares `1` and `3`. No swap. The `swapped` flag remains `false`.
  - The algorithm terminates because the list is now sorted.
  - **After Pass 4:** `[1, 3, 5, 6, 7, 8]`

  **Final Sorted Array:** `[1, 3, 5, 6, 7, 8]`
</details>

<details>
  <summary><b>4. Compare Bubble Sort, Insertion Sort, and Selection Sort based on their time complexity and stability.</b></summary>
  
  | Algorithm | Best-Case Time | Average-Case Time | Worst-Case Time | Stable? |
  | :--- | :--- | :--- | :--- | :--- |
  | **Bubble Sort** | O(n) (with flag) | O(n²) | O(n²) | Yes |
  | **Insertion Sort**| O(n) | O(n²) | O(n²) | Yes |
  | **Selection Sort**| O(n²) | O(n²) | O(n²) | No |

  **Summary:**
  - **Time Complexity:** All three have an average and worst-case time complexity of O(n²), making them inefficient for large datasets. However, Bubble Sort and Insertion Sort have a best-case complexity of O(n) if the data is already sorted, making them adaptive. Selection Sort is not adaptive; its performance is always O(n²).
  - **Stability:** Bubble Sort and Insertion Sort are stable algorithms because they only swap adjacent elements and do not skip over elements. Selection Sort is unstable because it finds the minimum element and swaps it with an element that could be far away, potentially changing the relative order of equal elements.
</details>
