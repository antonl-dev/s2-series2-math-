# Module 4.4: Quick Sort

## 1. Introduction to Quick Sort

Quick Sort is a highly efficient, in-place, comparison-based sorting algorithm that also uses the **Divide and Conquer** paradigm. It is often faster in practice than other O(n log n) algorithms like Merge Sort, primarily due to its in-place nature which leads to better cache performance.

The key to Quick Sort is the **partitioning** step. The algorithm works by selecting an element from the array, called the **pivot**, and partitioning the other elements into two subarrays according to whether they are less than or greater than the pivot. The subarrays are then sorted recursively.

## 2. The Quick Sort Algorithm

### How It Works

1.  **Divide:**
    -   **Choose a Pivot:** Select an element from the array. Common choices include the first element, the last element, the middle element, or a random element.
    -   **Partition:** Reorder the array so that all elements with values less than the pivot come before it, while all elements with values greater than the pivot come after it. After this partitioning, the pivot is in its final sorted position. This process is called the **partition** operation.

2.  **Conquer:** Recursively apply Quick Sort to the subarray of elements with smaller values and to the subarray of elements with larger values.

3.  **Combine:** No work is needed to combine the subarrays. Because the partitioning step places the pivot in its correct final position, and the recursive calls sort the subarrays, the entire array becomes sorted once the recursion finishes.

### The Partitioning Process (Lomuto Partition Scheme)

One of the most common and intuitive partitioning schemes is the Lomuto partition scheme. It works as follows (assuming the pivot is chosen as the last element):

1.  Take the last element of the array as the pivot.
2.  Initialize a pointer `i` (the partition index) to one position before the start of the array (`i = low - 1`).
3.  Iterate through the array from `low` to `high - 1` with a pointer `j`.
4.  If the element `arr[j]` is less than or equal to the pivot, increment `i` and swap `arr[i]` with `arr[j]`. This step effectively moves all smaller elements to the left side of the partition.
5.  After the loop, swap the pivot element (`arr[high]`) with the element at `arr[i + 1]`. This places the pivot in its final sorted position.
6.  Return the partition index `i + 1`.

[**Google Image Search:** `quicksort lomuto partition animation`](https://www.google.com/search?tbm=isch&q=quicksort+lomuto+partition+animation)
*   **What to look for:** A visualization where a pivot (often the last element) is chosen. The animation shows two pointers moving through the array, swapping elements to group smaller ones on the left. Finally, the pivot is swapped into the middle.

### C Code Implementation

```c
#include <stdio.h>

void swap(int* a, int* b) {
    int t = *a;
    *a = *b;
    *b = t;
}

/* This function takes last element as pivot, places the pivot element at its
   correct position in sorted array, and places all smaller (smaller than pivot)
   to left of pivot and all greater elements to right of pivot */
int partition(int arr[], int low, int high) {
    int pivot = arr[high]; // pivot
    int i = (low - 1);     // Index of smaller element

    for (int j = low; j <= high - 1; j++) {
        // If current element is smaller than or equal to pivot
        if (arr[j] <= pivot) {
            i++; // increment index of smaller element
            swap(&arr[i], &arr[j]);
        }
    }
    swap(&arr[i + 1], &arr[high]);
    return (i + 1);
}

/* The main function that implements QuickSort
   arr[] --> Array to be sorted,
   low   --> Starting index,
   high  --> Ending index */
void quickSort(int arr[], int low, int high) {
    if (low < high) {
        // pi is partitioning index, arr[p] is now at right place
        int pi = partition(arr, low, high);

        // Separately sort elements before partition and after partition
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}

void printArray(int arr[], int size) {
    for (int i = 0; i < size; i++)
        printf("%d ", arr[i]);
    printf("\n");
}

int main() {
    int arr[] = {35, 10, 50, 25, 40};
    int n = sizeof(arr) / sizeof(arr[0]);
    
    printf("Unsorted array: \n");
    printArray(arr, n);

    quickSort(arr, 0, n - 1);
    
    printf("Sorted array: \n");
    printArray(arr, n);
    return 0;
}
```

### Complexity Analysis

-   **Time Complexity:**
    -   **Worst Case: O(n²)**. This occurs when the partitioning process is highly unbalanced. For example, if the pivot is always the smallest or largest element (which happens if the array is already sorted or reverse-sorted and the first/last element is chosen as the pivot). The array is split into one subarray of size `n-1` and another of size `0`, leading to quadratic complexity.
    -   **Average Case: O(n log n)**. This occurs when the partitioning process is reasonably well-balanced. The array is split into two subarrays of roughly equal size, leading to a recursion depth of `log n`.
    -   **Best Case: O(n log n)**. This occurs when the pivot is always the median element, splitting the array into two perfectly equal halves.

-   **Space Complexity:** **O(log n)** on average, **O(n)** in the worst case.
    -   Although Quick Sort is an in-place algorithm (it doesn't create new arrays for data), it requires space on the call stack for the recursive calls. In the average case, the recursion depth is `log n`. In the worst case (unbalanced partitions), the recursion depth can be `n`.

### Characteristics

-   **In-place:** Yes.
-   **Stable:** No. The partitioning process can change the relative order of equal elements by swapping them with distant elements.
-   **Algorithm Paradigm:** Divide and Conquer.

---

### Questions

<details>
  <summary><b>1. Describe the partitioning process in Quick Sort.</b></summary>
  
  The partitioning process is the core of the Quick Sort algorithm. Its goal is to rearrange a subarray around a chosen **pivot** element. After partitioning, three conditions are met:
  1. The pivot element is in its final, correct sorted position.
  2. All elements to the left of the pivot are less than or equal to the pivot.
  3. All elements to the right of the pivot are greater than the pivot.

  A common method is the **Lomuto partition scheme**:
  1.  **Select Pivot:** Choose a pivot (e.g., the last element of the subarray).
  2.  **Rearrange:** Iterate through the subarray. Maintain a pointer for the boundary of elements smaller than the pivot. Whenever an element smaller than the pivot is found, swap it into this "smaller" section.
  3.  **Place Pivot:** After checking all other elements, swap the pivot into the position immediately following the "smaller" section.
  4.  **Return Pivot Index:** The new index of the pivot is returned, so the `quickSort` function knows the boundaries for its recursive calls on the left and right subarrays.
</details>

<details>
  <summary><b>2. Apply Quick Sort to arrange the seat numbers `{35, 10, 50, 25, 40}`. Show the partitioning at each step. (Use the last element as the pivot).</b></summary>
  
  **Initial Array:** `[35, 10, 50, 25, 40]`

  **Call 1: `quickSort(arr, 0, 4)`**
  - **Pivot:** `40`
  - The `partition` function will rearrange the array `[35, 10, 50, 25]` around `40`.
  - Elements `<= 40`: `35, 10, 25`.
  - After partitioning, the array becomes: `[35, 10, 25, 40, 50]`
  - The pivot `40` is now at index 3.
  - **Recursive Calls:**
    1. `quickSort(arr, 0, 2)` for subarray `[35, 10, 25]`
    2. `quickSort(arr, 4, 4)` for subarray `[50]` (base case, returns)

  **Call 2: `quickSort(arr, 0, 2)` on `[35, 10, 25]`**
  - **Pivot:** `25`
  - Partitioning `[35, 10]` around `25`.
  - After partitioning, the subarray becomes: `[10, 25, 35]`
  - The pivot `25` is now at index 1.
  - **Recursive Calls:**
    1. `quickSort(arr, 0, 0)` for subarray `[10]` (base case, returns)
    2. `quickSort(arr, 2, 2)` for subarray `[35]` (base case, returns)

  All recursive calls have returned. The array is now fully sorted.
  **Final Sorted Array:** `[10, 25, 35, 40, 50]`
</details>

<details>
  <summary><b>3. Explain why Quick Sort's worst-case time complexity is O(n²) while its average case is O(n log n).</b></summary>
  
  The efficiency of Quick Sort depends entirely on how well the pivot divides the array.

  - **Average Case (O(n log n)):** In the average case, the pivot chosen will be somewhere in the middle of the sorted data, dividing the array into two roughly equal halves. The problem of size `n` is broken into two subproblems of size `n/2`. This leads to a recursion depth of `log n`. Since the partition step takes O(n) time at each level, the total time is O(n log n).

  - **Worst Case (O(n²)):** The worst case occurs when the partitioning is extremely unbalanced. This happens if the pivot is always the smallest or largest element in the subarray. For example, if the array is already sorted (or reverse-sorted) and the last element is always chosen as the pivot. In this scenario, the array of size `n` is split into one subarray of size `0` and another of size `n-1`. The recursion depth becomes `n` instead of `log n`. Since the partition step still takes O(n) time, the total complexity becomes O(n * n) = O(n²).
</details>

<details>
  <summary><b>4. Compare Quick Sort and Merge Sort.</b></summary>
  
  | Feature | Quick Sort | Merge Sort |
  | :--- | :--- | :--- |
  | **Time Complexity** | **Average:** O(n log n)<br>**Worst:** O(n²) | **All cases:** O(n log n) |
  | **Space Complexity** | O(log n) average (for recursion stack) | O(n) (for temporary arrays) |
  | **In-place?** | Yes | No |
  | **Stability** | No | Yes |
  | **Performance** | Generally faster in practice for typical inputs due to being in-place (better cache locality). | More consistent performance. Guaranteed O(n log n) time makes it suitable for worst-case scenarios. |
  | **Paradigm** | Divide and Conquer | Divide and Conquer |
</details>
