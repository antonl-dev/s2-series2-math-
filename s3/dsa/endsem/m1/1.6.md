
# Module 1: Basic Concepts of Data Structures

## 1.5 Complexity Calculation of Simple Algorithms

This section applies the analysis rules we've learned to full, simple algorithms. The goal is to move from analyzing single lines or loops to determining the overall complexity of a complete piece of logic. We will use examples directly from your question papers to make this as practical as possible.

### 1. Step-by-Step Process for Complexity Calculation

1.  **Identify the Input Size:** Determine the variable that represents the size of the input, usually denoted as `n`. For an array, `n` is the number of elements.
2.  **Analyze Individual Statements:** Assign a complexity of `O(1)` to all simple statements (assignments, arithmetic, etc.).
3.  **Analyze Loops:**
    *   For a simple `for` loop that runs `n` times, the complexity is `O(n)`.
    *   For nested loops, multiply the complexities of the outer and inner loops. (e.g., `n` iterations * `m` iterations = `O(n*m)`).
    *   For loops where the counter grows exponentially (e.g., `i = i * 2`), the complexity is logarithmic, `O(log n)`.
4.  **Analyze Recursive Functions:** The complexity depends on the number of recursive calls and the work done at each call. The space complexity is often determined by the maximum depth of the recursion stack.
5.  **Combine and Simplify:** Add the complexities of sequential blocks and take the dominant term. For example, `O(n) + O(n²) = O(n²)`.

### 2. Example 1: Simple Linear Algorithm (From Internal Test 1)

**Problem:** Find the complexity of the following code:
```c
int fun(int n) {
    int i, count = 0; // O(1)
    for (i = 0; i < n; i++) { // Loop runs n times
        count++; // O(1) operation
    }
    return count; // O(1)
}
```
**Analysis:**
1.  **Input Size:** The input size is `n`.
2.  **Initialization:** The statements `int i, count = 0;` are `O(1)`.
3.  **Loop:** The `for` loop starts at `i=0` and runs until `i` is no longer less than `n`. This means the loop body executes exactly **n** times.
4.  **Loop Body:** The operation inside the loop, `count++`, is a simple statement and takes `O(1)` time.
5.  **Return Statement:** The `return count;` statement is `O(1)`.

**Total Time Complexity:**
*   We sum the complexities: `O(1)` (initialization) + `n * O(1)` (loop) + `O(1)` (return).
*   `T(n) = 1 + n + 1 = n + 2`.
*   Using asymptotic analysis, we drop the constant `2` and the coefficient of `n` (which is 1).
*   The final complexity is **O(n)**.

### 3. Example 2: Insertion Sort Algorithm (From End Sem Exam)

Insertion sort is a simple sorting algorithm that builds the final sorted array one item at a time.

**Algorithm (Pseudocode):**
```
procedure insertionSort(A : list of sortable items)
   n = length(A)
   for i = 1 to n-1 do
      key = A[i]
      j = i - 1
      while j >= 0 and A[j] > key do
         A[j+1] = A[j]
         j = j - 1
      end while
      A[j+1] = key
   end for
end procedure
```
**Analysis:**
This algorithm has a nested loop structure, but the inner `while` loop's execution depends on the input data, so we must analyze the best and worst cases.

*   **Worst-Case Analysis:**
    *   **Scenario:** This occurs when the input array is sorted in **reverse order**.
    *   **Reasoning:** For each element `A[i]`, the `while` loop must compare it with all the already sorted elements before it (`A[0]` through `A[i-1]`) and shift them all one position to the right.
    *   The outer loop runs `n-1` times. In the worst case, the inner loop runs `i` times for each `i`.
    *   Total comparisons/shifts ≈ `1 + 2 + 3 + ... + (n-1) = n(n-1)/2`.
    *   This expression is dominated by the `n²` term.
    *   **Worst-Case Time Complexity: O(n²)**

*   **Best-Case Analysis:**
    *   **Scenario:** This occurs when the input array is **already sorted**.
    *   **Reasoning:** For each element `A[i]`, the condition `A[j] > key` in the `while` loop will be false on the very first check. The inner loop does not execute its body at all.
    *   The outer loop runs `n-1` times, and for each iteration, only a single comparison is made in the `while` loop.
    *   **Best-Case Time Complexity: O(n)**

*   **Average-Case Analysis:**
    *   **Scenario:** The input array is in a random, jumbled order.
    *   **Reasoning:** On average, for each element `A[i]`, the inner `while` loop will have to scan and shift about half of the already sorted elements. This also results in a quadratic growth rate.
    *   **Average-Case Time Complexity: O(n²)**

[Click here for an animated visualization of Insertion Sort](https://www.google.com/search?tbm=isch&q=insertion+sort+algorithm+visualization+gif)
**What to look for:** An animation showing an array being sorted. Notice how for each element, it's picked up and "inserted" into the correct position in the sorted part of the array on the left by shifting other elements.

---

### Questions

1.  Write the algorithm for insertion sort and perform a detailed analysis of its best case, worst case, and average case complexities. (From *End Sem Exam*)
2.  Find the complexity of the following code, which calculates `a` raised to the power of `b`. Explain how you arrived at the answer.
    ```c
    int power(int a, int b) {
        if (b == 0) {
            return 1;
        }
        return a * power(a, b - 1);
    }
    ```
3.  What is the time complexity of a simple algorithm that finds the maximum element in an unsorted array of `n` elements?

<details>
<summary>Click to see Answers</summary>

---

#### Answer to Question 1

**Algorithm for Insertion Sort (Pseudocode):**
```
procedure insertionSort(A)
   for i from 1 to length(A)-1
      key = A[i]
      j = i - 1
      while j >= 0 and A[j] > key
         A[j+1] = A[j]
         j = j - 1
      A[j+1] = key
```

**Complexity Analysis:**

*   **Best Case:** O(n)
    *   This occurs when the array is already sorted. The outer loop runs `n-1` times. The inner `while` loop's condition `(A[j] > key)` is false immediately for every `i`, so it only performs one comparison per iteration of the outer loop. This results in a linear number of operations.

*   **Worst Case:** O(n²)
    *   This occurs when the array is sorted in reverse order. For each pass `i` of the outer loop, the element `A[i]` must be compared with all `i` elements before it and shifted to the very beginning. The number of comparisons is roughly the sum `1 + 2 + ... + (n-1)`, which is `n(n-1)/2`. This is dominated by the `n²` term.

*   **Average Case:** O(n²)
    *   For a randomly ordered array, on average, each element `A[i]` will have to be compared with and shifted past about half of the elements in the sorted portion. The number of operations is still proportional to `n²`.

---

#### Answer to Question 2

The given code is a recursive function to calculate `a^b`.
```c
int power(int a, int b) {
    if (b == 0) { // Base Case
        return 1;
    }
    // Recursive Step
    return a * power(a, b - 1);
}
```
**Analysis:**

1.  **Time Complexity: O(b)**
    *   The function's runtime depends on the value of `b`.
    *   In each recursive step, `b` is decremented by 1 (`power(a, b-1)`).
    *   The function stops when `b` reaches the base case `b == 0`.
    *   This means the function will call itself `b` times. For example, `power(a, 3)` calls `power(a, 2)`, which calls `power(a, 1)`, which calls `power(a, 0)`.
    *   Since the number of operations is directly proportional to `b`, the time complexity is **O(b)**.

2.  **Space Complexity: O(b)**
    *   Each recursive call adds a new frame to the call stack.
    *   The maximum depth of the recursion is `b`.
    *   Therefore, the space complexity is also **O(b)**, as it needs space on the stack for each of the `b` pending function calls.

---

#### Answer to Question 3

To find the maximum element in an unsorted array of `n` elements, you must examine every element at least once.

**Algorithm:**
1. Initialize a variable `max_val` to the first element of the array. (1 operation)
2. Loop through the rest of the array from the second element to the last (`n-1` times).
3. In each iteration, compare the current element with `max_val`. If it's larger, update `max_val`. (1 comparison per iteration)

**Analysis:**
*   You perform `n-1` comparisons.
*   The total number of operations is proportional to `n`.
*   Therefore, the time complexity is **O(n)**. This is true for the best, worst, and average cases, because no matter how the data is arranged, you must inspect every element to be sure you have found the maximum.

</details>
